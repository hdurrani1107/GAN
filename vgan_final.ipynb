{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CelebA dataset stored on student google drive. Need to mount drive in order to access"
      ],
      "metadata": {
        "id": "Y9uh0B72l1JJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2SWx1WUlh1K"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some reason, torchmetrics wouldn't be recognized by Colab, so I needed to write this line"
      ],
      "metadata": {
        "id": "PscdDcjUl2vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade torchmetrics[image] torch-fidelity\n",
        "\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "\n",
        "print(\"torchmetrics is available:\", FrechetInceptionDistance, InceptionScore)"
      ],
      "metadata": {
        "id": "Vms5vN4Ol3PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entire VGAN code"
      ],
      "metadata": {
        "id": "juWLPbrPmG7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------\n",
        "#  Import Libraries\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "import os, glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torchvision import transforms\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Hyperparameters\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#Directory to save VGAN results\n",
        "save_root = \"/content/drive/MyDrive/celeb/Results_VGAN\"\n",
        "os.makedirs(save_root, exist_ok=True)\n",
        "\n",
        "#For sweeping uncomment the list and for loop\n",
        "#lr_list = [2e-4, 2e-5, 2e-6] -> Chosen lr = 2e-4\n",
        "#z_list  = [64, 100, 128] -> Chosen z-dim = 100\n",
        "lr = 2e-4\n",
        "z_dim = 100\n",
        "batch_size = 64\n",
        "img_size   = 64\n",
        "img_dim    = 3 * img_size * img_size\n",
        "#Swept through hyperparameters at 50 epochs to get results, keeping at 50 epochs\n",
        "epochs     = 50\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Classes\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "#Loads in CelebA dataset from Path\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        pattern = os.path.join(root_dir, \"**\", \"*.jpg\")\n",
        "        self.paths = glob.glob(pattern, recursive=True)\n",
        "        if not self.paths:\n",
        "            raise RuntimeError(f\"No images found: {pattern}\")\n",
        "        print(f\"Found {len(self.paths)} images\")\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(img) if self.transform else img\n",
        "\n",
        "\n",
        "#Generator Class\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, hidden=256, img_dim=3*64*64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim, hidden),\n",
        "            nn.ReLU(False),\n",
        "            nn.Linear(hidden, hidden*2),\n",
        "            nn.ReLU(False),\n",
        "            nn.Linear(hidden*2, img_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(z)\n",
        "\n",
        "\n",
        "#Discriminator Class\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim=3*64*64, hidden=256):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(img_dim, hidden*2),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Linear(hidden*2, hidden),\n",
        "            nn.LeakyReLU(0.2, inplace=False),\n",
        "            nn.Linear(hidden, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "\n",
        "#Transforms images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "#Dataset pathway specified here: had three locations celeb2500, celeb5000, and celeb10000\n",
        "dataset = CelebADataset('/content/drive/MyDrive/celeb/celeb10000', transform=transform)\n",
        "loader  = DataLoader(dataset, batch_size=batch_size, shuffle=True,\n",
        "                     num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Main Loop\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#Uncomment for loops for hyperparameter testing\n",
        "#for lr in lr_list:\n",
        "    #for z_dim in z_list:\n",
        "print(f\"\\n=== RUN: lr={lr}, z_dim={z_dim} ===\")\n",
        "run_dir = os.path.join(save_root, f\"lr_{lr}_z_{z_dim}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Build models\n",
        "G = Generator(z_dim=z_dim, img_dim=img_dim).to(device)\n",
        "D = Discriminator(img_dim=img_dim).to(device)\n",
        "#Optimize\n",
        "opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5,0.999))\n",
        "#Metrics\n",
        "criterion   = nn.BCELoss()\n",
        "fid_metric  = FrechetInceptionDistance(feature=2048).to(device)\n",
        "is_metric   = InceptionScore(feature=2048).to(device)\n",
        "\n",
        "# Store Scores\n",
        "loss_D_list, loss_G_list = [], []\n",
        "fid_scores, inception_scores = [], []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(1, epochs+1):\n",
        "    G.train(); D.train()\n",
        "    running_D, running_G = 0.0, 0.0\n",
        "\n",
        "    for real_flat in loader:\n",
        "        real = real_flat.view(-1, img_dim).to(device)\n",
        "        bsz  = real.size(0)\n",
        "        real_labels = torch.ones(bsz,1, device=device)\n",
        "        fake_labels = torch.zeros(bsz,1, device=device)\n",
        "\n",
        "        # Discriminator step\n",
        "        D.zero_grad()\n",
        "        loss_D_real = criterion(D(real), real_labels)\n",
        "        fake_flat   = G(torch.randn(bsz, z_dim, device=device))\n",
        "        loss_D_fake = criterion(D(fake_flat.detach()), fake_labels)\n",
        "        (loss_D_real + loss_D_fake).backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        # Generator step\n",
        "        G.zero_grad()\n",
        "        loss_G = criterion(D(fake_flat), real_labels)\n",
        "        loss_G.backward()\n",
        "        opt_G.step()\n",
        "\n",
        "        running_D += (loss_D_real + loss_D_fake).item()\n",
        "        running_G += loss_G.item()\n",
        "\n",
        "    # Compute Averages\n",
        "    avg_D = running_D / len(loader)\n",
        "    avg_G = running_G / len(loader)\n",
        "    loss_D_list.append(avg_D)\n",
        "    loss_G_list.append(avg_G)\n",
        "\n",
        "    G.eval()\n",
        "    # Prepare real_uint8\n",
        "    real_list = []\n",
        "    for flat in loader:\n",
        "        real_list.append(flat)\n",
        "        if len(real_list)*batch_size >= 1000:\n",
        "            break\n",
        "    real_eval = torch.cat(real_list)[:1000].to(device)\n",
        "    real_eval = ((real_eval + 1)/2).view(-1,3,img_size,img_size)\n",
        "    real_uint8 = (real_eval * 255).to(torch.uint8)\n",
        "\n",
        "    # Fake_uint8 + grid\n",
        "    with torch.no_grad():\n",
        "        noise     = torch.randn(1000, z_dim, device=device)\n",
        "        fake_flat = G(noise)\n",
        "        fake_eval = ((fake_flat.view(-1,3,img_size,img_size).cpu() + 1)/2)\n",
        "        fake_uint8 = (fake_eval * 255).to(torch.uint8)\n",
        "        grid = make_grid(fake_eval, nrow=8, padding=2, normalize=True)\n",
        "\n",
        "        # uncommented for speed\n",
        "        # save this epoch's generated grid\n",
        "        # save_image(grid, os.path.join(run_dir, \"fake_epoch_{epoch}.png\"))\n",
        "\n",
        "    # Compute FID\n",
        "    fid_metric.reset()\n",
        "    fid_metric.update(real_uint8, real=True)\n",
        "    fid_metric.update(fake_uint8.to(device), real=False)\n",
        "    fid_val = fid_metric.compute().item()\n",
        "    fid_scores.append(fid_val)\n",
        "\n",
        "    # Compute Inception Score\n",
        "    is_metric.reset()\n",
        "    is_metric.update(fake_uint8.to(device))\n",
        "    is_val, _ = is_metric.compute()\n",
        "    inception_scores.append(is_val.item())\n",
        "\n",
        "    # Print all metrics\n",
        "    print(f\"Epoch {epoch}/{epochs} | \"\n",
        "          f\"D_loss {avg_D:.3f} | G_loss {avg_G:.3f} | \"\n",
        "          f\"FID {fid_val:.3f} | IS {is_val:.3f}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "#  Plot and save graphs\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "#Change names based on dataset size\n",
        "\n",
        "epochs_range = list(range(1, epochs+1))\n",
        "\n",
        "# FID curve\n",
        "plt.figure()\n",
        "plt.plot(epochs_range, fid_scores)\n",
        "plt.title(f\"FID for 10000 Images\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"FID\"); plt.grid(True)\n",
        "plt.savefig(os.path.join(run_dir, \"fid10000.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Inception Score curve\n",
        "plt.figure()\n",
        "plt.plot(epochs_range, inception_scores)\n",
        "plt.title(f\"Inception Score for 10000 Images\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"IS\"); plt.grid(True)\n",
        "plt.savefig(os.path.join(run_dir, \"is10000.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Loss curves\n",
        "plt.figure()\n",
        "plt.plot(epochs_range, loss_G_list, label=\"Gen Loss\")\n",
        "plt.plot(epochs_range, loss_D_list, label=\"Disc Loss\")\n",
        "plt.title(f\"Losses for 10000 Images\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"BCE Loss\")\n",
        "plt.legend(); plt.grid(True)\n",
        "plt.savefig(os.path.join(run_dir, \"losses10000.png\"))\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "#  Generate final Image\n",
        "# ---------------------------------------------------------------------\n",
        "with torch.no_grad():\n",
        "    n_samples = 64\n",
        "    noise     = torch.randn(n_samples, z_dim, device=device)\n",
        "    fake_flat = G(noise)\n",
        "    fake_imgs = ((fake_flat.view(-1,3,img_size,img_size).cpu() + 1)/2)\n",
        "\n",
        "final_path = os.path.join(run_dir, \"final_samples10000.png\")\n",
        "save_image(fake_imgs, final_path, nrow=8, padding=2, normalize=True)\n",
        "\n",
        "# inline display\n",
        "grid = make_grid(fake_imgs, nrow=8, padding=2, normalize=True)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(grid.permute(1,2,0))\n",
        "plt.title(f\"Final 8Ã—8 Samples at 10000 Images\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0M5SDgEkmHRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
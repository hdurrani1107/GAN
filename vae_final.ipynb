{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CelebA dataset stored on student google drive. Need to mount drive in order to access"
      ],
      "metadata": {
        "id": "MmAqdFt5ofFi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKw44RaMoaL3"
      },
      "outputs": [],
      "source": [
        "# MOUNT GOOGLE DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some reason, torchmetrics wouldn't be recognized by Colab, so I needed to write this line"
      ],
      "metadata": {
        "id": "QWXz6KgVofbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade torchmetrics[image] torch-fidelity\n",
        "\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "\n",
        "print(\"torchmetrics is available:\", FrechetInceptionDistance, InceptionScore)"
      ],
      "metadata": {
        "id": "OxQUlA00of8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main VAE code"
      ],
      "metadata": {
        "id": "E2trgBsZogJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------------------\n",
        "#  Import Libraries\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Hyperparameters\n",
        "# -------------------------------------------------------------------------------\n",
        "batch_size    = 64\n",
        "learning_rate = 2e-4\n",
        "epochs        = 50\n",
        "latent_dim    = 100\n",
        "image_size    = 64\n",
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# -----------------------\n",
        "# Show Images during training\n",
        "# -----------------------\n",
        "def show_images(img_batch, title=None):\n",
        "    grid = make_grid(img_batch, nrow=8, normalize=True)\n",
        "    np_grid = grid.permute(1, 2, 0).cpu().numpy()\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(np_grid)\n",
        "    plt.axis('off')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# Dataset Load\n",
        "# -----------------------\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.files = glob(os.path.join(root_dir, '*.jpg'))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "#Transform Images\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(178),\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "\n",
        "#Where Dataset is located on student drive\n",
        "data_dir      = '/content/drive/MyDrive/celeb/celeb5000'\n",
        "train_dataset = CelebADataset(data_dir, transform=transform)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                           shuffle=True, num_workers=2)\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# VAE Class\n",
        "# -------------------------------------------------------------------------------\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Conv2d(3, 32, 4, 2, 1)\n",
        "        self.enc2 = nn.Conv2d(32, 64, 4, 2, 1)\n",
        "        self.enc3 = nn.Conv2d(64, 128, 4, 2, 1)\n",
        "        self.enc4 = nn.Conv2d(128, 256, 4, 2, 1)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc_mu     = nn.Linear(256*4*4, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256*4*4, latent_dim)\n",
        "        # Decoder\n",
        "        self.fc_dec = nn.Linear(latent_dim, 256*4*4)\n",
        "        self.dec4   = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
        "        self.dec3   = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
        "        self.dec2   = nn.ConvTranspose2d(64, 32, 4, 2, 1)\n",
        "        self.dec1   = nn.ConvTranspose2d(32,  3, 4, 2, 1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = F.relu(self.enc2(x))\n",
        "        x = F.relu(self.enc3(x))\n",
        "        x = F.relu(self.enc4(x))\n",
        "        x = self.flat(x)\n",
        "        return self.fc_mu(x), self.fc_logvar(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        return mu + torch.randn_like(std) * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = F.relu(self.fc_dec(z)).view(-1, 256, 4, 4)\n",
        "        x = F.relu(self.dec4(x))\n",
        "        x = F.relu(self.dec3(x))\n",
        "        x = F.relu(self.dec2(x))\n",
        "        return torch.tanh(self.dec1(x))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "# Loss Function\n",
        "# -------------------------------------------------------------------------------\n",
        "def vae_loss(recon, x, mu, logvar):\n",
        "    recon_l = F.mse_loss(recon, x, reduction='sum')\n",
        "    kld     = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_l + kld\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Model, Optimizer, and Metrics\n",
        "# -------------------------------------------------------------------------------\n",
        "model         = VAE(latent_dim).to(device)\n",
        "optimizer     = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "fid_metric    = FrechetInceptionDistance().to(device)\n",
        "is_metric     = InceptionScore().to(device)\n",
        "\n",
        "# Store results for graphs\n",
        "loss_history      = []\n",
        "fid_history       = []\n",
        "inception_history = []\n",
        "sample_collection = []\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Training Loop\n",
        "# -------------------------------------------------------------------------------\n",
        "start_time = time.time()\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon, mu, logvar = model(imgs)\n",
        "        loss = vae_loss(recon, imgs, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_dataset)\n",
        "    loss_history.append(avg_loss)\n",
        "    print(f'Epoch {epoch:03d}  Avg Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Generate samples for this epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z       = torch.randn(64, latent_dim, device=device)\n",
        "        sample  = model.decode(z)\n",
        "\n",
        "        # Store raw float samples for later use\n",
        "        sample_collection.append(sample.cpu())\n",
        "\n",
        "        # Convert to uint8 for metrics\n",
        "        sample_uint8 = ((sample.clamp(-1,1) + 1) * 127.5).to(torch.uint8)\n",
        "        real_batch   = next(iter(train_loader)).to(device)\n",
        "        real_uint8   = ((real_batch.clamp(-1,1) + 1) * 127.5).to(torch.uint8)\n",
        "\n",
        "        # Inception Score\n",
        "        is_metric.update(sample_uint8)\n",
        "        is_val, _ = is_metric.compute()\n",
        "        inception_history.append(is_val.item())\n",
        "        is_metric.reset()\n",
        "\n",
        "        # FID Score\n",
        "        fid_metric.update(real_uint8, real=True)\n",
        "        fid_metric.update(sample_uint8, real=False)\n",
        "        fid_val = fid_metric.compute()\n",
        "        fid_history.append(fid_val.item())\n",
        "        fid_metric.reset()\n",
        "\n",
        "        #Print result out every Epoch\n",
        "        print(f\"Epoch {epoch}/{epochs} | Avg Loss: {avg_loss:.4f} | \"\n",
        "              f\"FID {fid_val:.3f} | IS {is_val:.3f}\")\n",
        "\n",
        "        # Optional: display sample grid inline\n",
        "        #Can comment in or out\n",
        "        #show_images(sample, title=f'Epoch {epoch:03d} Samples')\n",
        "\n",
        "#Calculate time\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\nTraining complete in {elapsed/60:.2f} minutes.\")\n",
        "\n",
        "# -------------------------------------------------------------------------------\n",
        "#  Plot Figures\n",
        "# -------------------------------------------------------------------------------\n",
        "\n",
        "# Loss Plot\n",
        "plt.figure()\n",
        "plt.plot(range(1, epochs+1), loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('VAE Training Loss over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#IS Plot\n",
        "plt.figure()\n",
        "plt.plot(range(1, epochs+1), inception_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Inception Score')\n",
        "plt.title('Inception Score over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#FID Plot\n",
        "plt.figure()\n",
        "plt.plot(range(1, epochs+1), fid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('FID Score')\n",
        "plt.title('FID Score over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "1EHwrMlyoisy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}